**Phase 1 Prompt for BSE UDP Market Data Reader Python Project:**

You are an expert Python developer specializing in financial data feeds, network programming, and protocol parsing. This is Phase 1 of a multi-phase project to build a complete Python project called "bse_udp_reader". The overall goal is to connect to the Bombay Stock Exchange (BSE) via UDP multicast using the Direct NFCAST protocol (low bandwidth interface), receive real-time market data packets, decode and decompress them, extract touch line data (e.g., open, high, low, close, LTP, volume, bid, ask) and market depth data (best 5 bid/ask levels) from message types 2020 and 2021, and save to JSON and CSV.

**Standards to Follow in This and All Future Prompts:**
- Always adhere to the project structure provided below.
- Use a .venv virtual environment for all development; install dependencies inside it.
- Read and incorporate details from all provided documents, including the full PDFs "BOLTPLUS Connectivity Manual V1.14.1.pdf" (connection parameters in section 5, routes in section 4, multicast setup with IGMPv2) and "BSE_DIRECT_NFCAST_Manual.pdf" (protocol details in sections 2-5, message layouts, compression in section 5, big-endian byte order, buffer size 2000 bytes).
- For connections, use multicast IPs/ports from PDFs (e.g., Production Equity NFCAST: 227.0.0.21:12996; make configurable in config.json, default to simulation/test for safety: Equity simulation NFCAST 226.1.0.1:11401).
- Track progress: In README.md, include "What We Did" (e.g., created structure, venv, connection logic), "What We Will Do" (e.g., next phases for receiving/decoding), and TODO.md with checkboxes.
- Explain everything: Use detailed code comments, docstrings, and README sections for connection (UDP multicast join, IGMPv2), what's done/not done (e.g., Phase 1: structure and connection done; decoding not yet).
- Error handling: Log connections, handle socket errors.
- Testing: Add basic tests in tests/.
- Running: Via `python src/main.py` (for now, establish connection and log success).

**Phase 1 Focus: Project Base Setup and Connection**
- Create the project structure.
- Set up .venv and requirements.txt (socket, struct, json, csv, datetime).
- Read all documents carefully: Extract connection IPs/ports/routes from BOLTPLUS (e.g., Equity production NFCAST details); note NFCAST deviations (leading zeros, mixed endian) from other docs; confirm no authentication needed for NFCAST (multicast join only).
- Implement connection: In connection.py, create UDP socket, set reuseaddr, bind, join multicast group (use struct.pack for mreq), set recv buffer to 2000 bytes. Use Equity segment for starters.
- In main.py, load config, establish connection, log "Connection established to BSE NFCAST", run infinite loop to recv (but don't process yet—placeholder for future phases).
- Track: What's done (structure, venv, connection); not done (receiving, decoding, saving—planned for later phases).

**Project Structure:**
```
bse_udp_reader/
├── .venv/                  # Virtual environment
├── src/
│   ├── __init__.py
│   ├── connection.py       # UDP multicast socket setup and join
│   ├── packet_receiver.py  # Placeholder for receiving packets
│   ├── decoder.py          # Placeholder for decoding
│   ├── decompressor.py     # Placeholder for decompression
│   ├── data_collector.py   # Placeholder for data extraction
│   ├── saver.py            # Placeholder for JSON/CSV saving
│   └── main.py             # Orchestrates connection (Phase 1); will add more later
├── data/
│   ├── raw_packets/        # For future raw dumps
│   ├── processed_json/     # For future JSON
│   └── processed_csv/      # For future CSV
├── docs/
│   ├── BSE_Final_Analysis_Report.md
│   ├── BSE_NFCAST_Analysis.md
│   ├── BSE_Complete_Technical_Knowledge_Base.md
│   ├── BOLTPLUS Connectivity Manual V1.14.1.pdf
│   └── BSE_DIRECT_NFCAST_Manual.pdf
├── tests/
│   ├── test_connection.py  # Test socket join
│   ├── test_decoder.py     # Placeholder
│   └── test_decompressor.py # Placeholder
├── requirements.txt         # socket, struct, etc. (standard libs)
├── README.md                # Project explanation, progress
├── TODO.md                  # TODO list with checkboxes
└── config.json              # Multicast IP/port, segment (e.g., {"ip": "227.0.0.21", "port": 12996})
```

**Step-by-Step TODO for Phase 1 (Implement Sequentially):**
1. Create project folder and structure.
2. Create/activate .venv, generate requirements.txt.
3. Copy docs into docs/.
4. In connection.py: Implement UDP multicast join based on PDFs.
5. In main.py: Load config, call connection, log success, infinite recv loop (print packet len).
6. Update README/TODO with progress.

Generate the project: Create/populate all files for Phase 1. Output as code snippets or ZIP description.


===========================================================================================================
**Phase 2 Prompt for BSE UDP Market Data Reader Python Project:**

You are an expert Python developer specializing in financial data feeds, network programming, and protocol parsing. This is Phase 2 of the multi-phase project "bse_udp_reader". Building on Phase 1 (where we set up the project structure, .venv, config, and basic UDP multicast connection in connection.py), we now focus on receiving raw packets from the BSE pipeline, filtering for message types 2020 (Market Picture) and 2021 (Market Picture Complex), assuring they are correct, extracting tokens from them, and storing both raw packets and extracted tokens for future phases. The overall goal remains: connect via UDP multicast to BSE Direct NFCAST (low bandwidth), receive packets, decode/decompress, extract touch line and market depth data, and save to JSON/CSV.

**Standards to Follow in This and All Future Prompts:**
- Always adhere to the project structure from Phase 1.
- Use the .venv virtual environment; assume it's activated and dependencies installed (add 'logging' to requirements.txt if not there—standard lib).
- Read and incorporate details from all provided documents, including the full PDFs "BOLTPLUS Connectivity Manual V1.14.1.pdf" (use connection parameters from section 5, e.g., Production Equity NFCAST: IP 227.0.0.21, port 12996; DR same; routes in section 4 for IGMPv2 multicast) and "BSE_DIRECT_NFCAST_Manual.pdf" (protocol in sections 2-5: UDP unreliable, self-contained packets, big-endian except deviations; buffer 2000 bytes from page 15; message types 2020/2021 compressed from page 22; no recovery needed from page 9).
- For connections/receiving: Use multicast IP/port from PDFs (configurable in config.json, default to Production Equity NFCAST 227.0.0.21:12996 for real data; warn if market closed—hours 9:00-15:30 IST from docs). Handle UDP nature: delayed/missing/duplicated packets (log but process all).
- Track progress: Update README.md with "What We Did" (e.g., added receiving, filtering, storage; Phase 1 connection integrated), "What We Will Do" (e.g., Phase 3: decoding/decompression), and TODO.md with checkboxes (mark Phase 1 done, add Phase 2 items).
- Explain everything: Deep code comments/docstrings (e.g., why recvfrom(2000)—from manual; how filter types: parse header offsets from analysis docs like BSE_Complete_Technical_Knowledge_Base.md: offset 0-3 zeros, 8-9 LE type 0x07E4 for 2020). In README: explain receiving (infinite loop, filter 2020/2021, extract tokens at offset 36+ LE uint32, store in data/raw_packets/ as .bin files and tokens in JSON).
- Error handling/Logs: Use logging module (import logging; configure in main.py to file/console with levels DEBUG/INFO/ERROR). Log connection success, packet received (len, addr), type check (valid/invalid), token extraction, storage, and errors (e.g., socket timeouts, invalid headers). This tracks where stuck (e.g., "No packets: market closed?").
- Testing: Add test_packet_receiver.py (mock socket.recvfrom with sample packets from docs).
- Running: Main entry point is python src/main.py—it loads config, establishes connection (from Phase 1), starts receiving loop, filters/stores. Assure: Check packet validity (size 300/556 from analysis, leading zeros), log "Received valid 2020 packet with tokens: [list]".

**Phase 2 Focus: Receiving Packets, Filtering, Extracting Tokens, and Storage**
- Assume Phase 1 done: connection.py joins multicast, main.py calls it and logs success.
- Implement receiving: In packet_receiver.py, infinite loop with sock.recvfrom(2000), get packet/addr.
- Filter for 2020/2021: Parse header (36 bytes from knowledge base: offset 0:4 zeros==b'\x00\x00\x00\x00', 4:2 format ID (0x0124/0x022C BE), 8:2 type LE (0x07E4=2020, adjust for 2021=0x07E5? from manual page 22: 2021). If matches, proceed; else log discard.
- Extract tokens: For valid packets, parse records starting offset 36, every 64 bytes (up to 6); token at +0:4 LE uint32 (from analysis: non-zero valid, e.g., 842364 test).
- Store: Raw packets in data/raw_packets/ as timestamped .bin (e.g., 20251003_135214_packet.bin). Extracted tokens per packet in JSON (e.g., {"timestamp": "...", "msg_type": 2020, "tokens": [842364, ...]} ) in data/processed_json/tokens.json (append mode). This prepares for Phase 3 decoding.
- Assure correctness: Log packet details; if no packets, mention "Ensure market open (9AM-3:30PM IST), correct IP/port, IGMP enabled" from manuals.
- Deep Explanation: UDP recv unreliable—handle partial/invalid (check len>=36, header matches deviations from final_analysis.md). Tokens LE while others BE (mixed from docs). Storage for debugging/next phases.
- What's Done/Not Done: Done: Connection+receiving+filter+extract/store (Phase 1+2). Not Done: Full decode/decompress (Phase 3), data collection/save (Phase 4). If forget packets: Explicitly add "Receive and store at least 10 packets before proceeding" in TODO.

**Project Structure:** (Unchanged from Phase 1; update files as needed)
```
bse_udp_reader/
├── .venv/                  # Virtual environment
├── src/
│   ├── __init__.py
│   ├── connection.py       # UDP multicast setup (from Phase 1)
│   ├── packet_receiver.py  # New: Receives, filters 2020/2021, extracts tokens, stores
│   ├── decoder.py          # Placeholder
│   ├── decompressor.py     # Placeholder
│   ├── data_collector.py   # Placeholder
│   ├── saver.py            # Placeholder (will use for JSON in this phase)
│   └── main.py             # Updated: Calls connection, then packet_receiver loop
├── data/
│   ├── raw_packets/        # Store .bin raw packets here
│   ├── processed_json/     # Store tokens JSON here
│   └── processed_csv/      # For future
├── docs/                   # Unchanged
├── tests/
│   ├── test_connection.py  # From Phase 1
│   ├── test_packet_receiver.py # New: Mock receiving/filtering
│   └── test_decompressor.py # Placeholder
├── requirements.txt         # Add logging if needed
├── README.md                # Update progress
├── TODO.md                  # Update checkboxes
└── config.json              # Add "segment": "equity", "store_limit": 100 (max packets to store)
```

**Step-by-Step TODO for Phase 2 (Implement Sequentially):**
1. Update main.py: Load config, call connection.get_socket(), pass to packet_receiver.receive_loop(sock).
2. In packet_receiver.py: Infinite loop recvfrom(2000), log packet len/addr.
3. Filter: Parse header for type 2020/2021; if valid, log "Valid packet received".
4. Extract tokens: Loop records, get LE tokens, collect list; assure non-zero/valid.
5. Store: Write raw to .bin, append tokens dict to JSON; log "Stored packet and tokens".
6. Add logging: Configure in main.py; track stuck (e.g., timeout=5s on recv).
7. Update README/TODO: Mark Phase 2 done, note remaining.

Generate the project updates: Modify existing files, add new code for Phase 2. Output as code snippets or ZIP description.
==========================================================================================================

**Phase 3 Prompt for BSE UDP Market Data Reader Python Project:**

You are an expert Python developer specializing in financial data feeds, network programming, and protocol parsing. This is Phase 3 of the multi-phase project "bse_udp_reader". Building on Phase 1 (project setup, .venv, and UDP multicast connection) and Phase 2 (receiving packets, filtering for 2020/2021 message types, extracting tokens, and storing raw packets/tokens), we now focus on decoding the stored packets, decompressing the compressed sections for 2020/2021 messages, extracting touch line data (open, prev_close, high, low, ltp, volume, best_bid, best_ask) and market depth data (best 5 bid/ask levels with prices, quantities, orders, implied qty), normalizing (e.g., prices /100 to rupees), and saving the processed data to both JSON and CSV. The overall goal is a complete project: connect to BSE Direct NFCAST, receive/filter packets, decode/decompress, collect data, and save.

**Standards to Follow in This and All Future Prompts:**
- Always adhere to the project structure from previous phases.
- Use the .venv virtual environment; assume it's activated and dependencies installed (add 'csv' and 'json' if not in requirements.txt—standard libs; use logging for tracking).
- Read and incorporate details from all provided documents, including the full PDFs "BOLTPLUS Connectivity Manual V1.14.1.pdf" (connection params in section 5, e.g., Equity NFCAST IP/port; no auth for NFCAST) and "BSE_DIRECT_NFCAST_Manual.pdf" (protocol in sections 2-5: compression for 2020/2021 only from Open Rate onwards, pages 48-55: differential 2-byte values, bases LTP/LTQ, special 32767/full read, 32766/-32766 end markers, dynamic cascading bases for best 5; big-endian except deviations; UDP self-contained).
- For decoding/decompression: Follow deviations from other docs (BSE_Final_Analysis_Report.md: leading 0x00000000, format ID 0x0124/0x022C, mixed endian—tokens LE uint32 at offset 36+, prices BE; fixed 64-byte records; field mapping corrections like position 8=prev_close). Header 36 bytes, records every 64 bytes up to 6. Decompress: Uncompressed up to Close Rate + LTQ + LTP, then compressed fields (open, prev_close, high, low, etc.) using diffs + bases; best 5 with cascading (level1 base LTP/LTQ, level2 base level1, etc.).
- Track progress: Update README.md with "What We Did" (e.g., added decoding/decompression, data extraction/save; Phases 1-3 integrated for full run), "What We Will Do" (e.g., enhancements like symbol resolution), and TODO.md with checkboxes (mark Phases 1-2 done, add Phase 3 items).
- Explain everything: Deep code comments/docstrings (e.g., decompression function: "Read 2-byte signed diff, if 32767 read full 4-byte, else base + diff; from manual p49"). In README: explain full flow (connection -> receive/filter/store raw -> decode header/records -> decompress compressed parts -> extract/normalize touch line/depth -> save JSON/CSV). Assure Phases 1-2 work: In main.py, add checks (e.g., if no packets stored, log "Phase 2 failed: No packets—check market hours/connection").
- Error handling/Logs: Enhance logging (DEBUG for packet details, INFO for success, ERROR for issues like invalid diff/decompression fail). Log every step: "Decoding packet: size X", "Decompressing field Y: value Z", "Extracted data for token T", "Saved to JSON/CSV", "Issue: Invalid header—skipping". Track fetching issues (e.g., "No 2020 packets: Market closed? IP wrong?").
- Code Readability: Use clear variable names (e.g., base_ltp, diff_value), functions (e.g., decompress_field(base, packet, offset)), PEP8 style, docstrings. Modular: decoder.py for header/token parse, decompressor.py for diff logic/best5.
- Testing: Add test_decoder.py and test_decompressor.py (mock packets from knowledge base/code examples in docs, assert extracted values match expected).
- Running: Main entry point python src/main.py—full flow: load config, connect (Phase1), receive/filter/extract/store raw/tokens (Phase2 infinite loop), then for each valid packet: decode, decompress, collect data, save to JSON (list of dicts per instrument: {"token":, "timestamp":, "open":, "high":, ... , "bid_levels": [{"price":, "qty":, ...}, ...]}) and CSV (columns: token, timestamp, open, high, ..., bid1_price, bid1_qty, ... ask5_orders; append rows). Timestamped files in data/processed_json/ and processed_csv/ (e.g., 20251003_quotes.json/csv). Run indefinitely, process in real-time.

**Phase 3 Focus: Decoding, Decompression, Data Extraction, and Saving**
- Assume Phases 1-2 working: main.py already connects, receives, filters 2020/2021, stores raw .bin and tokens JSON. Now, integrate: After filtering/extracting in packet_receiver.py, pass packet to decoder.decode_packet(packet) -> decompressor.decompress_records(decoded_data) -> data_collector.collect_quotes(decompressed) -> saver.save_to_json_csv(quotes).
- Decoding: In decoder.py, parse header (36 bytes: check zeros, format ID for size 300/556, type LE, timestamp from offsets 20-25 BE). Then records: for num_records (from header or fixed up to 6), at offsets 36,100,... parse token LE, then uncompressed fields up to LTP (e.g., num_trades BE, volume BE, close_rate BE, ltq BE, ltp BE from manual layouts p48+).
- Decompression: In decompressor.py, start after LTP: for compressed fields (open, prev_close, high, low, reserved, indicative_eq_price, etc.) use _decompress_field(base_ltp/ltq, packet, offset) handling specials. Then best5 buy/sell loops: decompress levels with cascading bases (stop at 32766/-32766). Normalize prices /100.
- Data Collection: In data_collector.py, per record build dict with touch line (from fields) and depth (lists of dicts for bid/ask levels).
- Saving: In saver.py, append to JSON (json.dump with indent=4 for readability) and CSV (csv.writer, header row if new file).
- Assure Completeness: Check Phases 1-2 (e.g., if stored packets exist/load for offline test). Handle 2020 (4-byte token) vs 2021 (8-byte). Log "Full decode success: Extracted X quotes".
- Deep Explanation: Decompression principal (manual p48: diff=base+signed_short, exceeds=32767->full; dynamic for best5 p50). Deviations (analysis: misleading fields, data issues like low LTP). Save both formats for flexibility (JSON structured, CSV tabular).
- What's Done/Not Done: Done: Full project flow (connect-receive-decode-decompress-save). Not Done: Advanced (e.g., subscription/auth if needed from BOLTPLUS, but NFCAST multicast no auth; symbol map from RDI).

**Project Structure:** (Unchanged; update files)
```
bse_udp_reader/
├── .venv/                  # Virtual environment
├── src/
│   ├── __init__.py
│   ├── connection.py       # Phase 1
│   ├── packet_receiver.py  # Phase 2: Updated to call decode/decompress/save
│   ├── decoder.py          # New: Header/record parsing
│   ├── decompressor.py     # New: Decompression logic
│   ├── data_collector.py   # New: Extract/normalize quotes
│   ├── saver.py            # New: JSON/CSV saving
│   └── main.py             # Updated: Full orchestration
├── data/
│   ├── raw_packets/        # Phase 2 .bin
│   ├── processed_json/     # Phase 2 tokens + New quotes JSON
│   └── processed_csv/      # New quotes CSV
├── docs/                   # Unchanged
├── tests/
│   ├── test_connection.py  # Phase 1
│   ├── test_packet_receiver.py # Phase 2
│   ├── test_decoder.py     # New
│   └── test_decompressor.py # New
├── requirements.txt         # Updated if needed
├── README.md                # Update progress
├── TODO.md                  # Update
└── config.json              # Add "subscribed_tokens": [842364], "market_hours_check": true
```

**Step-by-Step TODO for Phase 3 (Implement Sequentially):**
1. In packet_receiver.py: After filter/extract, call decoder.decode_packet(packet) -> return header, records.
2. In decoder.py: Parse header, loop records for uncompressed parts/token.
3. In decompressor.py: For each record, decompress compressed fields/best5, handle specials/cascading.
4. In data_collector.py: Build quote dicts, normalize.
5. In saver.py: Save quotes to JSON/CSV, timestamp files.
6. Update main.py: Integrate full chain in loop; add Phase1-2 checks (e.g., socket alive, packets received).
7. Enhance logs: Every step logged for issue tracking.
8. Update README/TODO: Mark Phase 3 done, note full project runnable.

Generate the project updates: Modify existing, add new code for Phase 3. Output as code snippets or ZIP description.

============================================================================================

**Phase 4 Prompt for BSE UDP Market Data Reader Python Project:**

You are an expert Python developer specializing in financial data feeds, network programming, and protocol parsing. This is Phase 4 of the multi-phase project "bse_udp_reader". Building on Phases 1-3 (Phase 1: project setup and connection; Phase 2: receiving/filtering/extracting/storing raw packets and tokens; Phase 3: decoding/decompressing/extracting touch line and market depth data/saving to JSON/CSV), this phase focuses on the remaining enhancements and final integration to ensure a robust, production-ready system. The overall goal is a fully functional project: connect to BSE Direct NFCAST via UDP multicast, receive/filter 2020/2021 packets, decode/decompress, extract normalized data (touch line: open, prev_close, high, low, ltp, volume, bid, ask; market depth: best 5 bid/ask levels), and save to JSON/CSV, with comprehensive logging and error handling.

**Standards to Follow in This and All Future Prompts:**
- Always adhere to the project structure from previous phases.
- Use the .venv virtual environment; assume it's activated and dependencies installed (requirements.txt includes logging, csv, json, datetime; add 'os' if needed for file handling).
- Read and incorporate details from all provided documents, including the full PDFs "BOLTPLUS Connectivity Manual V1.14.1.pdf" (connection parameters in section 5, e.g., Equity NFCAST IP 227.0.0.21:12996, routes in section 4, IGMPv2 setup) and "BSE_DIRECT_NFCAST_Manual.pdf" (protocol in sections 2-5: UDP unreliable, compression for 2020/2021 from Open Rate onwards, pages 48-55: differential decompression, dynamic bases, special markers 32767/±32766; market hours 9:00-15:30 IST from page 10).
- For enhancements: Integrate optional BOLTPLUS authentication (section 3) if needed (currently NFCAST multicast no auth per manual), add contract/symbol resolution via RDI (section 3.3.1), optimize performance (manual p15: <1ms parsing target), and handle data quality issues (e.g., low LTP from analysis).
- Track progress: Update README.md with "What We Did" (e.g., integrated all phases, added enhancements, assured full run), "What We Will Do" (e.g., real-time testing, WebSocket streaming), and TODO.md with checkboxes (mark Phases 1-3 done, add Phase 4 items).
- Explain everything: Deep code comments/docstrings (e.g., "Optimize recv loop: Batch process 100 packets to hit <1ms per manual p15"). In README: Explain full flow (connect-receive-decode-decompress-save with enhancements), assure Phases 1-3 work (e.g., load stored packets for offline test if live fails), and detail remaining parts (e.g., subscription via BOLTPLUS API not yet implemented).
- Error handling/Logs: Enhance logging (DEBUG for packet details, INFO for milestones, ERROR/WARNING for issues like market closure, invalid data). Log every step: "Connected", "Received X packets", "Decoded Y records", "Decompressed Z fields", "Saved to files", "Warning: LTP too low—validate", "Error: No packets—check hours/IP". Track issues (e.g., "Stuck: No data after 5min—market closed?").
- Code Readability: Maintain PEP8, clear names (e.g., normalized_price, depth_level), modular functions (e.g., validate_quote_data), consistent logging format (timestamp, level, message).
- Testing: Update tests/ with real packet scenarios (e.g., test_decoder.py for data quality checks, test_decompressor.py for edge cases like 32767).
- Running: Main entry point python src/main.py—full flow: load config, connect (Phase 1), receive/filter/extract/store (Phase 2), decode/decompress/collect/save (Phase 3), apply enhancements (Phase 4) in a real-time loop. Assure: Check market hours (current: 05:08 PM IST, Oct 03, 2025—market closed), handle offline mode with stored packets.

**Phase 4 Focus: Final Integration, Enhancements, and Assurance**
- Assume Phases 1-3 working: main.py runs full chain (connect-receive-decode-decompress-save). Now, enhance and assure:
  - **Integration Check:** In main.py, add pre-run validation: if no live packets (market closed 15:30 IST), load stored .bin from data/raw_packets/ for offline processing. Log "Switching to offline mode".
  - **Enhancements:**
    - **Data Quality:** In data_collector.py, add validation (e.g., if ltp < 10 and volume > 0, log "Suspicious LTP: X for token Y—cross-check market"; from analysis LTP=6.82 issue).
    - **Performance:** In packet_receiver.py, batch process (e.g., 100 packets) to hit <1ms parsing (manual p15); log "Processed batch of X packets in Yms".
    - **Symbol Resolution:** In data_collector.py, stub RDI integration (section 3.3.1): if token in config.json["subscribed_tokens"], map to symbol (e.g., 842364 -> "BSX SENSEX Future"); log "Resolved token X to Y".
    - **BOLTPLUS Auth (Optional):** In connection.py, add placeholder for REST API auth (manual section 3) if future subscription needed; log "Auth skipped—NFCAST multicast".
    - **Error Recovery:** In main.py, add reconnection logic (e.g., if socket.error, retry 3x with 5s delay); log "Reconnecting attempt X".
  - **Assurance:** Run full flow, log milestones (e.g., "Phase 1-3 completed, Phase 4 enhancements applied"). If issues (e.g., no 2020/2021 packets), log "Assurance failed: Check Phase 2 filtering or market status".
- **Remaining Parts:** Subscription via BOLTPLUS API (not in NFCAST manual but in BOLTPLUS section 3), advanced features (WebSocket streaming, historical cache) deferred to future.
- **Deep Explanation:** Market closure handling (current 17:08 IST > 15:30 IST); performance optimization (batch vs single packet); data quality (cross-reference with prev_close); RDI stub for scalability. Logs ensure traceability (e.g., "No depth data: End marker 32766 hit").

**Project Structure:** (Unchanged; update files)
```
bse_udp_reader/
├── .venv/                  # Virtual environment
├── src/
│   ├── __init__.py
│   ├── connection.py       # Phase 1 + Optional auth stub
│   ├── packet_receiver.py  # Phase 2 + Batch optimization
│   ├── decoder.py          # Phase 3
│   ├── decompressor.py     # Phase 3
│   ├── data_collector.py   # Phase 3 + Quality/Symbol
│   ├── saver.py            # Phase 3
│   └── main.py             # Updated: Full flow + Assurance
├── data/
│   ├── raw_packets/        # Phase 2 + Offline source
│   ├── processed_json/     # Phase 3
│   └── processed_csv/      # Phase 3
├── docs/                   # Unchanged
├── tests/
│   ├── test_connection.py  # Phase 1
│   ├── test_packet_receiver.py # Phase 2
│   ├── test_decoder.py     # Phase 3
│   └── test_decompressor.py # Phase 3
├── requirements.txt        # Updated if needed
├── README.md               # Update progress
├── TODO.md                 # Update
└── config.json             # Add "batch_size": 100, "retry_attempts": 3
```

**Step-by-Step TODO for Phase 4 (Implement Sequentially):**
1. In main.py: Add offline mode check, integrate full flow.
2. In packet_receiver.py: Implement batch processing.
3. In data_collector.py: Add data validation, symbol stub.
4. In connection.py: Add auth placeholder, reconnection logic.
5. Enhance logging across all files for milestones/issues.
6. Update tests/ with new scenarios.
7. Update README/TODO: Mark Phase 4 done, note future plans.

Generate the project updates: Modify existing, add enhancements. Output as code snippets or ZIP description.
===============================================================================================
**Phase 4 Prompt for BSE UDP Market Data Reader Python Project (Final Assurance and Enhancements):**

You are an expert Python developer specializing in financial data feeds, network programming, and protocol parsing. This is Phase 4 of the multi-phase project "bse_udp_reader". Building on Phases 1-3 (Phase 1: project setup and UDP multicast connection; Phase 2: receiving/filtering/extracting/storing raw packets and tokens; Phase 3: decoding/decompressing/extracting touch line and market depth data/saving to JSON/CSV), this phase focuses on final assurance, enhancing the system for Equity Derivatives and Futures & Options (F&O) market depth and touch line data, verifying all processes (especially token saving and data extraction), and adding comprehensive logging to track every step and troubleshoot issues. The overall goal is a fully functional, production-ready project: connect to BSE Direct NFCAST via UDP multicast, process 2020/2021 packets, extract normalized data (touch line: open, prev_close, high, low, ltp, volume, bid, ask; market depth: best 5 bid/ask levels), and save to JSON/CSV, with robust error handling and logging.

**Standards to Follow in This and All Future Prompts:**
- Always adhere to the project structure from previous phases.
- Use the .venv virtual environment; assume it's activated and dependencies installed (requirements.txt includes logging, csv, json, datetime, os; ensure all standard libs are covered).
- Read and incorporate details from all provided documents, including the full PDFs "BOLTPLUS Connectivity Manual V1.14.1.pdf" (connection parameters in section 5.2 for Equity Derivatives: IP 227.0.0.22:12997, F&O multicast groups; routes in section 4; IGMPv2 setup) and "BSE_DIRECT_NFCAST_Manual.pdf" (protocol in sections 2-5: compression for 2020/2021 from Open Rate onwards, pages 48-55: differential decompression with LTP/LTQ bases, special markers 32767/±32766, dynamic best 5 bases; market hours 9:00-15:30 IST from page 10; buffer size 2000 bytes).
- For enhancements: Switch to Equity Derivatives segment (section 5.2) for F&O data, validate token saving (ensure all extracted tokens are stored in JSON), assure data completeness (touch line and depth for 2020/2021), and optimize logging for issue tracking.
- Track progress: Update README.md with "What We Did" (e.g., switched to Derivatives, verified token saving, enhanced logging), "What We Will Do" (e.g., real-time testing, RDI integration), and TODO.md with checkboxes (mark Phases 1-3 done, add Phase 4 items).
- Explain everything: Deep code comments/docstrings (e.g., "Switch to Derivatives IP: 227.0.0.22:12997 from manual 5.2"). In README: Explain full flow with Derivatives focus, assure Phases 1-3 work (e.g., load stored packets if live fails), detail logs for troubleshooting (e.g., "No tokens saved: Check Phase 2 extraction").
- Error handling/Logs: Use logging module (DEBUG for packet details, INFO for milestones, WARNING/ERROR for issues). Log every step: "Connected to Derivatives", "Received packet size X", "Extracted Y tokens", "Saved to JSON/CSV", "Warning: No depth data—end marker hit", "Error: Invalid packet—skipping". Track issues (e.g., "Stuck: No packets—market closed at 18:26 IST?").
- Code Readability: Maintain PEP8, clear names (e.g., derivatives_ip, token_list), modular functions (e.g., verify_token_saving), consistent logging (timestamp, level, message).
- Testing: Update tests/ with Derivatives scenarios (e.g., test_packet_receiver.py for 227.0.0.22:12997, test_decoder.py for F&O data validation).
- Running: Main entry point python src/main.py—full flow: load config, connect to Equity Derivatives, receive/filter/extract/store (Phase 2), decode/decompress/collect/save (Phase 3), verify tokens/data, log extensively. Assure: Check market hours (current: 18:26 IST, Oct 03, 2025—closed; use offline mode with stored packets).

**Phase 4 Focus: Final Assurance, Derivatives Switch, Token/Data Verification, and Logging**
- Assume Phases 1-3 working: main.py runs full chain (connect-receive-decode-decompress-save). Now, enhance and assure:
  - **Integration Check:** In main.py, validate Phases 1-3: if no live packets (market closed 15:30 IST), load stored .bin from data/raw_packets/ for offline processing. Log "Switching to offline mode with X packets".
  - **Switch to Equity Derivatives:** In connection.py, update config to use 227.0.0.22:12997 (manual 5.2) for F&O data. Log "Switched to Equity Derivatives NFCAST".
  - **Token Verification:** In packet_receiver.py and data_collector.py, ensure all extracted tokens (LE uint32 at offset 36+) are saved to data/processed_json/tokens.json. Add verify_token_saving() to check file against received packets; log "Verified X tokens saved" or "Warning: Y tokens missing".
  - **Data Completeness:** In data_collector.py, assure touch line (open, prev_close, high, low, ltp, volume, bid, ask) and market depth (best 5 bid/ask prices, qty, orders, implied qty) for 2020/2021. Validate against manual layouts (p48-55); log "Extracted complete data for token X" or "Error: Missing depth—check decompression".
  - **Logging Enhancement:** Add print/log statements everywhere (e.g., "Decoding record at offset 36", "Decompressing open rate: base LTP + diff", "Saving quote for token 842364"). Use consistent format (e.g., "[HH:MM:SS] [LEVEL] Message").
  - **Assurance:** Run full flow, log milestones (e.g., "Phase 4 complete: Derivatives data processed"). If issues (e.g., no 2020/2021 packets), log "Assurance failed: Check Derivatives IP/market hours".
  - **Remaining Parts:** Real-time subscription (BOLTPLUS API section 3), advanced features (WebSocket, caching) deferred.
- **Analysis of Logs:** From your run (18:08 IST, Oct 03, 2025), market closed (15:30 IST), using simulation (226.1.0.1:11401). Logs show connection success, 4944 tokens loaded, but no packet reception (loop stuck at "Starting packet reception loop..."—expected as market closed). Suggest switching to Derivatives and offline mode.

**Project Structure:** (Unchanged; update files)
```
bse_udp_reader/
├── .venv/                  # Virtual environment
├── src/
│   ├── __init__.py
│   ├── connection.py       # Phase 1 + Derivatives IP
│   ├── packet_receiver.py  # Phase 2 + Token verification
│   ├── decoder.py          # Phase 3
│   ├── decompressor.py     # Phase 3
│   ├── data_collector.py   # Phase 3 + Data completeness
│   ├── saver.py            # Phase 3
│   └── main.py             # Updated: Full flow + Assurance
├── data/
│   ├── raw_packets/        # Phase 2 + Offline source
│   ├── processed_json/     # Phase 2 tokens + Phase 3 quotes
│   └── processed_csv/      # Phase 3 quotes
├── docs/                   # Unchanged
├── tests/
│   ├── test_connection.py  # Phase 1
│   ├── test_packet_receiver.py # Phase 2 + Derivatives
│   ├── test_decoder.py     # Phase 3
│   └── test_decompressor.py # Phase 3
├── requirements.txt        # Updated if needed
├── README.md               # Update progress
├── TODO.md                 # Update
└── config.json             # Update "ip": "227.0.0.22", "port": 12997, "segment": "equity_derivatives"
```

**Step-by-Step TODO for Phase 4 (Implement Sequentially):**
1. In main.py: Add offline mode, validate Phases 1-3.
2. In connection.py: Switch to 227.0.0.22:12997.
3. In packet_receiver.py: Add verify_token_saving().
4. In data_collector.py: Ensure touch line/depth, validate data.
5. Enhance logging/print everywhere (e.g., "Processing packet at offset X").
6. Update tests/ with Derivatives cases.
7. Update README/TODO: Mark Phase 4 done, note future plans.

Generate the project updates: Modify existing, add enhancements. Output as code snippets or ZIP description.

====================================================================================================================

The current we get the data for the Equity segment is from the Production Equity NFCAST multicast group (IP: 227.0.0.22, Port: 12997).

so we haev to take the data for the equity derivatives segment from the Equity Derivatives NFCAST multicast group.

and we get the two types of the massage from the this multicast group 2020 and 2021.



Read both documents carefully. We have to get the token and extract the data for derivatives, i.e., **F&O (Futures and Options)** only. Currently, we might be working with **EQ (Equity)**, so now we need to focus on F&O data as well.

After decompression, the data looks something like this (example):

```
col1,col2,col3,col4,col5,col6,col7,col8,col9,col10,col11,col12,col13,col14,col15,col16,col17,col18,col19,col20,col21,col22,col23
"BSEFO",862244,2,SENSEX,SENSEX2591886900CE,IO,SENSEX-IO,12526100862244,20.05,0.05,1000,0.05,20,1,-1,SENSEX,2025-09-18T00:00:00,86900,3,SENSEX 18SEP2025 CE 86900,1,1,SENSEX2591886900CE
BSEFO,876601,2,BANKEX,BANKEX25OCT52500CE,IO,BANKEX-IO,12530300876601,11838.25,7810.65,900,0.05,30,1,-1,BANKEX,2025-10-30T00:00:00,52500,3,BANKEX 30OCT2025 CE 52500,1,1,BANKEX25OCT52500CE
BSEFO,872565,2,SENSEX,SENSEX25O0188500PE,IO,SENSEX-IO,12527400872565,8547.5,3279.3,1000,0.05,20,1,-1,SENSEX,2025-10-01T00:00:00,88500,4,SENSEX 01OCT2025 PE 88500,1,1,SENSEX25O0188500PE
```

This is just an example of how the data looks after decompression.

We need to focus only on the **Market Picture Broadcast messages [2020 and 2021]**.

* When we receive message type **2020**, the first 4 bytes are the scrip code.
* When we receive message type **2021**, it’s a converted Market Picture message and uses an **8-byte scrip code**.

See this comparison:

| Description              | NFCAST through IML                                                          | Direct NFCAST                                                         |
| ------------------------ | --------------------------------------------------------------------------- | --------------------------------------------------------------------- |
| 1. Reading Mode          | Broadcast mode.                                                             | Multicast mode.                                                       |
| 2. Packet Header         | 8-byte header (4-byte slot, 4-byte length).                                 | Read 2000 bytes; first 4 bytes is message type.                       |
| 3. Swapping              | Little endian format.                                                       | Big endian format (needs swapping).                                   |
| 4. Compression           | No decompression required.                                                  | Decompress Market Picture messages (2020, 2021, 2033).                |
| 5. Market Picture [2021] | IML converted message 2021 (8-byte scrip code) to 2020 (4-byte scrip code). | Application must handle message 2021 with 8-byte scrip code directly. |

These details are already mentioned in both `.txt` documents, so read them carefully.

Also refer to the example for decompression:

---

**5.9 Example of Decompression Logic**

**5.9.1 Example for General Decompression Mechanism**
Base Rate (LTP) = 1000

* **Open Rate**: Read 2 bytes = -500 → Final value = 1000 + (-500) = 500
* **Previous Close Rate**: Read 2 bytes = 32767 → This is an indicator → Read next 4 bytes = 40000 → Final value = 40000
* **High Rate**: Read 2 bytes = 0 → Final value = 1000 + 0 = 1000

**5.9.2 Example for Best 5 Structure Decompression Mechanism**
Instrument has one bid rate, no offer rate. Base LTP = 1000, Base LTQ = 10

* Best Bid Rate1: Read 2 bytes = 0 → Final value = 1000 + 0 = 1000
* Total Bid Qty1: Read 2 bytes = 15 → Final value = 10 + 15 = 25
* Bid at Price Points1: Read 2 bytes = -5 → Final value = 10 + (-5) = 5
* Implied Buy Qty1: Read 2 bytes = -10 → Final value = 10 + (-10) = 0
* Best Bid Rate2: Read 2 bytes = 32766 → Indicates end of Best Bid
* Best Offer Rate1: Read 2 bytes = -32766 → Indicates end of Best Offer

---

These examples are also mentioned in the documents.

* For the **connection and data extraction**, refer to:
  📄 **"BOLTPLUS Connectivity Manual V1.14.1.txt"**

* The main project documentation is:
  📄 **"BSE_DIRECT_NFCAST_Manual.txt"**
  This contains complete details such as:

  * Where and how to get the data
  * Logic for decompression
  * Examples for full Market Picture packet reading
  * Best 5 structure decompression
  * All implementation logic

We are focusing **only** on message types **2020** and **2021** — this includes both market picture and touchline data.

The decompression logic for these is on **Page 48 to 54** of the "BSE_DIRECT_NFCAST_Manual.txt" file. Please read that section carefully.

We should:

* Save the **token** in a separate file
* Save the **raw token data**
* Save the **message-wise CSV data**:

  * Messages of type **2020** → under the `2020/` directory
  * Messages of type **2021** → under the `2021/` directory




Rwead this both document carefully frist.


=============== 10-10-2025 ==================
now read those both ducument carefully.becuse we will have ro work for the derivites and may be we can cant decopration data correect way becuse some of the data i get missing as well , like symbol see the csv also , 

the dara we get like :
token,symbol,timestamp,open,high,low,close,ltp,volume,prev_close,bid_prices,bid_qtys,bid_orders,ask_prices,ask_qtys,ask_orders
1725340,UNKNOWN,2025-10-09 00:00:00,10403210.67,10403261.44,10403184.64,10403184.64,10403184.64,768,11240734.72,"10403184.64,10403476.49,10403476.49,10403476.49,10403476.49","0,0,4352,4352,3331","0,-7146,0,30465,0","10403192.32,10403192.32,10402885.46,10402885.46,10403202.91","0,27905,27905,27905,27905","0,0,5888,0,10275"
19640,UNKNOWN,2025-10-09 00:00:00,20814914.99,20814917.12,20814888.96,20814888.96,20814888.96,768,11240734.72,"20814888.96,20815093.91,20815093.91,20815093.91,20815093.91","0,0,256,256,5376","0,10240,0,-19441,0","20814891.52,20814891.52,20815045.12,20815045.12,20814863.51","0,17935,17935,17935,17935","0,0,256,0,5120"
57840,UNKNOWN,2025-10-09 00:00:00,13421772.8,13421772.8,13421746.89,13421772.8,13421772.8,16777216,167772.16,"13421772.8,13421775.36,13421775.36,13421457.95,13421457.95","20480,20480,18179,18179,18179","0,0,0,256,0","13421772.8,13421772.8,13421772.8,13421772.8,13421772.8","0,0,0,0,0","0,0,0,0,0"
175,UNKNOWN,2025-10-09 00:00:00,12127436.8,12127436.8,12127242.24,12127436.8,12127436.8,687865856,6878658.56,"12127436.8,12127552.0,12127552.0,12127491.24,12127491.24","-1971,-1971,-26547,-26547,-26547","0,0,0,10752,0","12127255.04,12127255.04,12127255.04,12127255.04,12127377.92","0,7168,7168,77,77","9275,0,-25856,0,0"
872958,UNKNOWN,2025-10-09 00:00:00,168030.78,167772.16,167823.36,167772.16,167772.16,335544320,-3325288.96,"167772.16,167772.16,167834.46,167834.46,167834.46","3922,3922,3922,3922,3922","768,-11541,0,0,0","167444.7,167444.7,167457.5,167475.42,167475.42","0,19456,19456,23378,24146","-28656,0,-28123,768,2588"



also we het the tocken may be rendom tocken must be we have to get the tocken something 8+lakh so may where we can get the data for sensex as well where we can het the symbol also .

here also you can see the timstem data as well this is all time wege the same tome may be that time stem we cant get perfecly so also focus ont this as well so check it thos both fiedl ussing read tyhose both doc. maty some where decompraton logic we cant cler so make it resolve this issue.


after resolve this issue make once file bu file and one hand documetetion for wole this project into the doc dir the fully gide and what the this project do the full off the doc . 

do the all task with todo list . 


also when we start the test or peoject sowe can try atlist the once tocken not with the all tocken becues we cant go with the all tocken for the testing we can take a latest.


================================================================================================================================


token,symbol,timestamp,open,high,low,close,ltp,volume,prev_close,bid_prices,bid_qtys,bid_orders,ask_prices,ask_qtys,ask_orders
878192,SENSEX25OCT237760000PE_PE__23OCT2025,2025-10-17 00:00:00,8556124.24,8556380.16,8556482.56,8556380.16,8556380.16,403374080,838860.8,"8556380.16,8556380.16,8556470.62,8556470.62,8556470.62","-18941,-18941,-18941,-18941,-18941","0,9075,0,0,0","8556053.15,8556053.15,8556065.95,8556065.95,8556065.95","0,17152,17152,42244,43012","6160,0,-11001,0,2353"
17280,UNKNOWN,2025-10-17 00:00:00,16444316.65,16444418.56,16444293.12,16444293.12,16444293.12,768,11240734.72,"16444293.12,16444618.27,16444618.27,16444618.27,16444618.27","0,0,256,256,10496","0,10240,0,22020,0","16444295.68,16444295.68,16444551.68,16444551.68,16444784.68","0,31235,31235,31235,31235","0,0,256,0,-3066"
545,UNKNOWN,2025-10-17 00:00:00,13421772.8,13421772.8,13421870.1,13421772.8,13421772.8,67108864,503316.48,"13421772.8,13421780.48,13421780.48,13422046.73,13422046.73","-23551,-23551,-24062,-24062,-47448","0,0,0,768,0","13421882.9,13421882.9,13421649.04,13421682.32,13421879.6","0,256,256,-1546,-1034","0,0,15974,256,6678"
1,UNKNOWN,2025-10-17 00:00:00,6860188.16,6859980.8,6859765.84,6859980.8,6859980.8,468156160,17168499.2,"6859980.8,6860032.0,6859704.32,6859795.07,6859795.07","19207,19207,19207,28253,28253","0,-2859,0,0,0","6859980.8,6859980.8,6860257.35,6860257.35,6860324.09","0,14345,14345,8564,-20876","0,0,17152,29440,-11168"
8440120,UNKNOWN,2025-10-17 00:00:00,16777216.0,16777216.0,16777456.17,16777216.0,16777216.0,16777216,167772.16,"16776888.32,16776890.88,16776890.88,16776993.28,16776993.28","5120,5120,-4939,-4939,-4939","0,0,-32768,256,0","16777468.97,16777468.97,16777468.97,16777141.29,16777143.85","-32768,-32512,-32512,-6912,-6912","5120,0,20402,0,0"
8442210,UNKNOWN,2025-10-17 00:00:00,16777216.0,16777216.0,16776903.21,16777216.0,16777216.0,16777216,167772.16,"16776888.32,16776890.88,16776890.88,16776942.08,16776942.08","25600,25600,44977,44977,29631","0,0,-32768,256,0","16777307.72,16777307.72,16777512.52","-32768,-32512,-32512","5120,0,0"
861455,SENSEX25OCT308150000CE_CE__30OCT2025,2025-10-17 00:00:00,1006888.96,1006632.96,1006684.16,1006632.96,1006632.96,2013265920,17869708.8,"1006632.96,1006632.96,1006723.42,1006723.42,1006723.42","-3840,-3840,-3840,-3840,-3840","1024,9075,0,0,0","1006694.41,1006694.41,1006989.26,1007007.18,1007007.18","0,17152,17152,12981,13749","-27646,0,-1958,768,2578"




see this csv data we get and store like this, we get and decoprase the data like this.

so we have to focuse on the decoprarion logic from the deocumentation reasd the documet care fully and get he tocken try with tye logicwith read deocmpararion 




frist read the this doc full od the so where we can get the decoprastion logic for the mssage types wise in ch.5 also into the dociumetation we also getthe tocken patternd for the tocu line data and decopration logic so read this doment frist with all pages , the atteched pdf is thense nfcast manual bse udp readr doc and the others is txt filr this is conver to pdf to tc\xt file . so pdf must preefer if you cant read pdf data so after that read the tst file documtations as well.


1. Market Picture Broadcast [2020 and 2021]:
4.8 Market Picture Broadcast [2020 and 2021] 
This message is sent by the Exchange whenever there is a change in the order book of an 
instrument/contract.  The  message  is  not  sent  on  every  update  in  the  order  book.  Instead,  it  is  sent 
whenever  there  is  a  change  in  a  defined  snapshot  interval.    The  interval  is  currently  defined  as  800 
milliseconds.  
To  optimally  use  the  network  resources,  updates  for  multiple  instrument/  contracts  is  packaged  in  a 
single market picture message. The market picture message is the most frequently sent message  and it 
has  the  largest  size.  Thus,  to  reduce  the  size  of  packet  over  the  network,  the  message  is  compressed 
further using native compression algorithm.  
The member application must apply the decompression algorithm to retrieve the message. The 
decompression logic is explained in detail in section Decompression of Market Picture Message. 
 


thisd is the Applicable Segment: All this is tabale into the page number 21 to 27 tyhis is a massage type 2020 and 2021.



now we read the ch :5 (the decmprastion logic of the tocken so also read this)
5 Decompression of Market Depth Message (page num : 48 to 54)

BSE applies the compression only on market picture messages viz Message type 2020 and 2021 only. All 
other  market  data  messages  can  be  read  from  the  socket  directly  as  per  the  structure  defined  in  API. 
The compression principle used is proprietary.

In case of market picture message, the entire market picture message is not sent in compressed format. 
For  each  record  present  in  the  market  picture  packet,  the  compression  starts  with  the  open  rate  field 
and ends with the last field for that record. All data points from open rates onwards are in compressed 
format. The decompression logic is detailed with an example in section  Example for full market picture 
reading 
 
It is suggested that the  user should read 2000 bytes of data by default  in a single read call.  This single 
read call will get single packet only. The first 4 bytes will convey the message type and depending upon 
the message  type  the  user  should  process  the  required messages  or  drop  the message  if  not  required. 
Since  the  size  of  market  picture  message  cannot  be  ascertained  due  to  compression  logic,  the  market 
picture message needs to be read byte by byte. It cannot be mapped to the structure directly as defined 
in the API. 
Binary values are presented in big-endian byte order, so the TPS application needs to convert it to little-
endian byte order. 
✓ Big-Endian  means  that  the  most  significant  byte  of  any  multibyte  data  field  is  stored  at  the 
lowest memory address, which is also the address of the larger field.  
✓ Little-Endian means that the least significant byte of any multibyte data field is stored at the 
lowest memory address, which is also the address of the larger field. 
5.1 Compression Principle 
 
The  idea  used  in  compression  is  that  rate  fields  in  the  structure  are  defined  as long  (4  bytes)  however 
since all the prices for an instrument usually operates in nearby range thus instead of using 4 bytes for 
each  price,  if  differential  value  with  respect  to  a  base  price  is  sent  then  the  differential  value  would 
generally be no exceeding 2 bytes capacity. Thus 2 bytes on each price field can be saved. Similar is the 
idea behind the quantity related field in the structure. 
5.2 Decompression Mechanism 
 
For decompression 2 fields are marked as base fields. One base field (LTP) is used for price and the other 
base field (LTQ) is used for Quantity. All the compressed fields contain the difference value with respect 
to base fields in 2 bytes. The user needs to add this 2-byte field value with the base field value to arrive 
the actual value of the next filed.  
In  case  the  difference  value  exceeds  2  bytes  then  the  actual  value  is  sent  in  next  4  bytes.  So,  for  all 
compressed fields the user needs to read 2 bytes first then depending upon the value in the 2 bytes field 
the user needs to decide what to do next.  
If the 2 bytes field value is 32767 the user needs to read the next 4 bytes to have the actual value as the 
diff  value  exceeds  2  bytes.  The  logic  is  explained  in  detail  with  an  example  in  the  example  section 
Example for full market picture packet reading 
5.3 Decompression Mechanism for Best 5 substructure 
 
In case of best 5 structures, 3 additional aspects are covered in decompression mechanism 
5.4 Reading Sequence 
 
The best 5 structure needs to be read for buy side and sell side independently i.e. the best 5 Bid 
structure is read first followed by best 5 offer structure. 
Read 5 Best Bid Fields in the following order i.e.  


✓ Best Bid Rate1, Total Bid Qty1, No. of   Bid at the price points1, Implied Buy Quantity 1 
✓ Best Bid Rate2, Total Bid Qty2, No. of   Bid at the price points2, Implied Buy Quantity 2 
✓ Best Bid Rate3, Total Bid Qty3, No. of   Bid at the price points3, Implied Buy Quantity 3 
✓ Best Bid Rate4, Total Bid Qty4, No. of   Bid at the price points4, Implied Buy Quantity 4 
✓ Best Bid Rate5, Total Bid Qty5, No. of   Bid at the price points5, Implied Buy Quantity 5 


Once 5 Best Bid Fields completed then start reading the 5 Best Offer Fields in similar order. 
5.5 Decompression logic  
 
The general decompression mechanism mentioned above holds true for best 5 structures also. 
Additionally, the base fields are used to decompress best 5 structure changes with each level.  
The base field used for different levels is different i.e. for e.g. the base fields used in level 1 are different 
than base fields used in level 2.  
For  each  level  the  base  fields  are  previous  level  field  values.  The  table  below  provides  the  base  filed 
used in each level for the buy side best 5 structures. 


Level 1 Best Bid 1 Best Bid Qty 1 No of orders 1 Implied Buy Qty 1 
         Base LTP LTQ LTQ LTQ 
Level 2 Best Bid 2 Best Bid Qty 2 No of orders 2 Implied Buy Qty 2 
          Base Best Bid 1 Best Bid Qty 1 No of orders 1 Implied Buy Qty 1 
Level 3 Best Bid 3 Best Bid Qty 3 No of orders 3 Implied Buy Qty 3 
          Base Best Bid 2 Best Bid Qty 2 No of orders 2 Implied Buy Qty 2 
Level 4 Best Bid 4 Best Bid Qty 4 No of orders 4 Implied Buy Qty 4 
         Base Best Bid 3 Best Bid Qty 3 No of orders 3 Implied Buy Qty 3 
Level 5 Best Bid 5 Best Bid Qty 5 No of orders 5 Implied Buy Qty 5 
        Base Best Bid 4 Best Bid Qty 4 No of orders 4 Implied Buy Qty 4 


Similar is the decompression logic for the sell side best 5 structures. 
5.6 Handling condition when no orders present at a price point 
 
In  the  best  5  structure,  it  is  possible  that  the  orders  may  not  be  present  on  all  5  price  points  thus  the 
price points  where  there are no  orders are present are not sent in  the  structure. Thus, during 
decompression of the best 5 substructure, additionally following logic needs to be also applied. 
If while reading the 5 Best Bid Fields if any Best Bid Rate is equals to 32766 then the remaining Best Bid 
Fields will not be present so 32766 indicates there are no more buy price points available in the book.  
Similarly,  while  reading  the  5  Best  Offer  Fields  if  any  Best  Offer  Rate  is  equals  to  -32766  then  the 
remaining 5 Best Offer Fields will not be present.  
5.7 Repetition of Instruments 
 
Once the compression of the first instrument is completed the user needs to know the number of bytes 
he has read. Let’s assume after the first instrument the number of bytes read as 160. 
So, the user needs to start reading 4 bytes from 160 bytes to get instrument code. Read the next 4 bytes 
for  number  of  trades  and  continue  till  compression  starts.  Store  the  base  values  in  memory  for  the 
second instrument. Then apply the compression logic. 


5.8 Summary of decompression mechanism 
 
✓ Identify the base values. 
✓ Store the base values in memory. 
✓ Read next 2 bytes and add the value to the base value to get final value.  
✓  If value is 32767 means diff value is exceeded, thus read next 4 bytes to have the actual 
value. 
 
For Best 5 structure Read 2 bytes 
✓ If value is 32767 means diff value is exceeded, thus read next 4 bytes to have the actual 
value. 
✓  If value is 32766 or -32766 means end of best bid or best offer. 
✓ The base value for level 1 is LTP and LTQ 
✓ The base value for all subsequent level (level n) is its previous level (level n-1 
5.9 Example of Decompression Logic  
 
Following are 3 examples explaining the decompression logic for the market picture message.  
5.9.1 Example for General Decompression Mechanism 
 
Let’s say base field for Rate is Last Traded Rate and its value is 1000. Open Rate as 500 and Previous 
Close Rate as 40000 and High Rate as 1000.


table :
Field Compressed/ Base Value Byte Action 
Last Traded Rate Base 1000 4 Read 4 bytes to get 1000 and store it in memory 
Open Rate Compressed -500 2 Read next 2 bytes to get -500 and apply it to LTR 
to get the final value as 500. 
Previous Close 
Rate 
Compressed 32767 
 
 
40000 
2 
 
 
4 
Read 2 bytes to get 32767 and this value is an 
indicator that diff value exceeds 2 bytes 
 
Read next 4 bytes to have the actual value 
40000. No need to apply base value. 
High Rate Compressed 0 2 Read next 2 bytes to get 0 and apply it to LTR to 
get the final value as 1000. 


5.9.2 Example for Best 5 structure decompression mechanism.  
 
For example, for an instrument only one bid rate and no offer rate are available as below. 
Best Bid Rate1 as 1000, Total Bid Qty1=25, No. of   Bid at the price points1= 5, Implied Buy Qty=0 and no 
Offer Rate 
Base LTP is 1000 and Base LTQ is 10

table of the decmpation :

Field       Compressed/Base      Value     Byte     Action

Last Traded Rate Base 1000 4 Assume already available in memory 
Last Traded 
Quantity 
Base 10 4 Assume already available in memory 
Best Bid Rate1 Compressed 0 2 Read next 2 bytes to get 0 and apply it to LTR 
to get the final value as 1000. 
Total Bid Qty1 Compressed 15 2 Read next 2 bytes to get 15 and apply it to LTQ 
to get the final value as 25. 
Bid at the price 
points1 
Compressed -5 2 Read next 2 bytes to get -5 and apply it to LTQ 
to get the final value as 5. 
Implied Buy 
Quantity 1 
Compressed -10 2 Read next 2 bytes to get -10 and apply it to 
LTQ to get the final value as 0. 
Best Bid Rate2 Compressed 32766 2 Read next 2 bytes to get 32766 indicates end 
of Best bid [Not available] 
Total Bid Qty2 Compressed NA 0 Not Available 
Bid at the price 
points2 
Compressed NA 0 Not Available 
Implied Buy 
Quantity 2 
Compressed NA 0 Not Available 
Best Bid Rate3 Compressed NA 0 Not Available 
Total Bid Qty3 Compressed NA 0 Not Available 
Bid at the price 
points3 
Compressed NA 0 Not Available 
Implied Buy 
Quantity 3 
Compressed NA 0 Not Available 
Best Bid Rate4 Compressed NA 0 Not Available 
Total Bid Qty4 Compressed NA 0 Not Available 
Bid at the price 
points4 
Compressed NA 0 Not Available 
Implied Buy 
Quantity 4 
Compressed NA 0 Not Available 
Best Bid Rate5 Compressed NA 0 Not Available 
Total Bid Qty5 Compressed NA 0 Not Available 
Bid at the price 
points5 
Compressed NA 0 Not Available 
Implied Buy 
Quantity 5 
Compressed NA 0 Not Available 
Best Offer Rate1 Compressed -32766 2 Read next 2 bytes to get -32766 indicates end 
of Best offer [Not available] 
Total Offer Qty1 Compressed NA 0 Not Available 
Offer at the price 
points1 
Compressed NA 0 Not Available 
Implied Sell 
Quantity 1 
Compressed NA 0 Not Available 





5.9.3 Example for full market picture packet reading


Field Name Type Action 
Message Type Long Read 4 bytes 
Reserved Field Long Read next 4 bytes 
Reserved Field Long Read next 4 bytes 
Reserved Field unsigne
d short 
Read next 2 bytes 
Hour Short Read next 2 bytes 
Minute Short Read next 2 bytes 
Second Short Read next 2 bytes 
Millisecond Short Read next 2 bytes 
Reserved Field Short Read next 2 bytes 
Reserved Field Short Read next 2 bytes 
No of Records Short Read next 2 bytes 
Following is a market picture structure appearing repeatedly (Max 5 times) 
Instrument Code Long Read next 4 bytes for message 2020 / 8 bytes for 2021 
No of Trades Unsigne
d Long 
Read next 4 bytes 
Volume Long 
Long 
Read next 8 bytes 
Value    Long 
Long 
Read next 8 bytes 
Trade Value Flag Char Read next 1 byte 
Trend Char Read next 1 byte 
Six Lakh Flag Char Read next 1 byte 
Reserved Field               Char Read next 1 byte 
Market Type Short Read next 2 bytes 
Session Number Short Read next 2 bytes 
LTP Hour Char Read next 1 byte 
LTP Minute Char Read next 1 byte 
LTP Second Char Read next 1 byte 
LTP Millisecond Char[3] Read next 3 bytes 
Reserved Field Char[2] Read next 2 bytes 
Reserved Field Short Read next 2 bytes 
Reserved Field Long 
Long 
Read next 8 bytes 
No of Price points Short Read next 2 bytes 
Timestamp Long 
Long 
Read next 8 bytes 
Close Rate Long Read next 4 bytes  
Last Trade Qty Long 
Long 
Read next 8 bytes and save as Qty base 

LTP   Long Read next 4 bytes and save as Rate base 
Open Rate Long Read next 2 bytes and apply compression logic with base as LTP 
Previous Close Rate Long Read next 2 bytes and apply compression logic with base as LTP 
High Rate Long Read next 2 bytes and apply compression logic with base as LTP 
Low Rate Long Read next 2 bytes and apply compression logic with base as LTP 
Reserved Field Long Read next 2 bytes and apply compression logic with base as LTP 
Indicative Equilibrium 
Price 
Long Read next 2 bytes and apply compression logic with base as LTP 
Indicative Equilibrium 
Qty 
Long 
Long 
Read next 2 bytes and apply compression logic with base as LTQ 
Total Bid Qty Long 
Long 
Read next 2 bytes and apply compression logic with base as LTQ 
Total Offer Qty Long 
Long 
Read next 2 bytes and apply compression logic with base as LTQ 
Lower Circuit Limit Long Read next 2 bytes and apply compression logic with base as LTP 
Upper Circuit Limit Long Read next 2 bytes and apply compression logic with base as LTP 
Weighted Average Long Read next 2 bytes and apply compression logic with base as LTP 
Following buy sub-structure will repeat number of times as specified in the “No. of Price points” field 
above or the buy sub structure will terminate if the value 32766 encountered. 
Best Bid Rate Long Read  next  2  bytes  and  apply  compression  logic  with  base  as  LTP.  
For level 2 base is 1st level and so on 
Total Bid Qty Long 
Long 
Read next 2 bytes and apply compression logic with base as LTQ. 
For level 2 base is 1st level and so on 
No. of   Bid at the 
price points 
Unsigne
d Long 
Read next 2 bytes and apply compression logic with base as LTQ. 
For level 2 base is 1st level and so on 
Implied Buy Quantity Long 
Long 
Read next 2 bytes and apply compression logic with base as LTQ. 
For level 2 base is 1st level and so on 
Reserved Field Long Read next 2 bytes and apply compression logic with base as LTQ. 
For level 2 base is 1st level and so on 
Following sell sub-structure will repeat number of times as specified in the “No. of Price points” field 
above or the sell sub structure will terminate if the value                 -32766 encountered. 
Best Offer Rate Long Read  next  2  bytes  and  apply  compression  logic  with  base  as  LTP.  
For level 2 base is 1st level and so on 
Total Offer Qty Long 
Long 
Read next 2 bytes and apply compression logic with base as LTQ. 
For level 2 base is 1st level and so on 
No. of Ask at the price 
point 
Unsigne
d Long 
Read next 2 bytes and apply compression logic with base as LTQ. 
For level 2 base is 1st level and so on 
Implied Sell Quantity Long 
Long 
Read next 2 bytes and apply compression logic with base as LTQ. 
For level 2 base is 1st level and so on 
Reserved Field Long Read next 2 bytes and apply compression logic with base as LTQ. 
For level 2 base is 1st level and so on



we have to use the testing the all the raw packges all packges and we ahev to do try for the decoprase thse all tockens as well also assuure for theshoued we get the currect value for the decmprase values or not so we ahev to check the upper given logic here as well for the testing we ahev to do decomprase all the packges in well stucture . 
