**Phase 1 Prompt for BSE UDP Market Data Reader Python Project:**

You are an expert Python developer specializing in financial data feeds, network programming, and protocol parsing. This is Phase 1 of a multi-phase project to build a complete Python project called "bse_udp_reader". The overall goal is to connect to the Bombay Stock Exchange (BSE) via UDP multicast using the Direct NFCAST protocol (low bandwidth interface), receive real-time market data packets, decode and decompress them, extract touch line data (e.g., open, high, low, close, LTP, volume, bid, ask) and market depth data (best 5 bid/ask levels) from message types 2020 and 2021, and save to JSON and CSV.

**Standards to Follow in This and All Future Prompts:**
- Always adhere to the project structure provided below.
- Use a .venv virtual environment for all development; install dependencies inside it.
- Read and incorporate details from all provided documents, including the full PDFs "BOLTPLUS Connectivity Manual V1.14.1.pdf" (connection parameters in section 5, routes in section 4, multicast setup with IGMPv2) and "BSE_DIRECT_NFCAST_Manual.pdf" (protocol details in sections 2-5, message layouts, compression in section 5, big-endian byte order, buffer size 2000 bytes).
- For connections, use multicast IPs/ports from PDFs (e.g., Production Equity NFCAST: 227.0.0.21:12996; make configurable in config.json, default to simulation/test for safety: Equity simulation NFCAST 226.1.0.1:11401).
- Track progress: In README.md, include "What We Did" (e.g., created structure, venv, connection logic), "What We Will Do" (e.g., next phases for receiving/decoding), and TODO.md with checkboxes.
- Explain everything: Use detailed code comments, docstrings, and README sections for connection (UDP multicast join, IGMPv2), what's done/not done (e.g., Phase 1: structure and connection done; decoding not yet).
- Error handling: Log connections, handle socket errors.
- Testing: Add basic tests in tests/.
- Running: Via `python src/main.py` (for now, establish connection and log success).

**Phase 1 Focus: Project Base Setup and Connection**
- Create the project structure.
- Set up .venv and requirements.txt (socket, struct, json, csv, datetime).
- Read all documents carefully: Extract connection IPs/ports/routes from BOLTPLUS (e.g., Equity production NFCAST details); note NFCAST deviations (leading zeros, mixed endian) from other docs; confirm no authentication needed for NFCAST (multicast join only).
- Implement connection: In connection.py, create UDP socket, set reuseaddr, bind, join multicast group (use struct.pack for mreq), set recv buffer to 2000 bytes. Use Equity segment for starters.
- In main.py, load config, establish connection, log "Connection established to BSE NFCAST", run infinite loop to recv (but don't process yet—placeholder for future phases).
- Track: What's done (structure, venv, connection); not done (receiving, decoding, saving—planned for later phases).

**Project Structure:**
```
bse_udp_reader/
├── .venv/                  # Virtual environment
├── src/
│   ├── __init__.py
│   ├── connection.py       # UDP multicast socket setup and join
│   ├── packet_receiver.py  # Placeholder for receiving packets
│   ├── decoder.py          # Placeholder for decoding
│   ├── decompressor.py     # Placeholder for decompression
│   ├── data_collector.py   # Placeholder for data extraction
│   ├── saver.py            # Placeholder for JSON/CSV saving
│   └── main.py             # Orchestrates connection (Phase 1); will add more later
├── data/
│   ├── raw_packets/        # For future raw dumps
│   ├── processed_json/     # For future JSON
│   └── processed_csv/      # For future CSV
├── docs/
│   ├── BSE_Final_Analysis_Report.md
│   ├── BSE_NFCAST_Analysis.md
│   ├── BSE_Complete_Technical_Knowledge_Base.md
│   ├── BOLTPLUS Connectivity Manual V1.14.1.pdf
│   └── BSE_DIRECT_NFCAST_Manual.pdf
├── tests/
│   ├── test_connection.py  # Test socket join
│   ├── test_decoder.py     # Placeholder
│   └── test_decompressor.py # Placeholder
├── requirements.txt         # socket, struct, etc. (standard libs)
├── README.md                # Project explanation, progress
├── TODO.md                  # TODO list with checkboxes
└── config.json              # Multicast IP/port, segment (e.g., {"ip": "227.0.0.21", "port": 12996})
```

**Step-by-Step TODO for Phase 1 (Implement Sequentially):**
1. Create project folder and structure.
2. Create/activate .venv, generate requirements.txt.
3. Copy docs into docs/.
4. In connection.py: Implement UDP multicast join based on PDFs.
5. In main.py: Load config, call connection, log success, infinite recv loop (print packet len).
6. Update README/TODO with progress.

Generate the project: Create/populate all files for Phase 1. Output as code snippets or ZIP description.


===========================================================================================================
**Phase 2 Prompt for BSE UDP Market Data Reader Python Project:**

You are an expert Python developer specializing in financial data feeds, network programming, and protocol parsing. This is Phase 2 of the multi-phase project "bse_udp_reader". Building on Phase 1 (where we set up the project structure, .venv, config, and basic UDP multicast connection in connection.py), we now focus on receiving raw packets from the BSE pipeline, filtering for message types 2020 (Market Picture) and 2021 (Market Picture Complex), assuring they are correct, extracting tokens from them, and storing both raw packets and extracted tokens for future phases. The overall goal remains: connect via UDP multicast to BSE Direct NFCAST (low bandwidth), receive packets, decode/decompress, extract touch line and market depth data, and save to JSON/CSV.

**Standards to Follow in This and All Future Prompts:**
- Always adhere to the project structure from Phase 1.
- Use the .venv virtual environment; assume it's activated and dependencies installed (add 'logging' to requirements.txt if not there—standard lib).
- Read and incorporate details from all provided documents, including the full PDFs "BOLTPLUS Connectivity Manual V1.14.1.pdf" (use connection parameters from section 5, e.g., Production Equity NFCAST: IP 227.0.0.21, port 12996; DR same; routes in section 4 for IGMPv2 multicast) and "BSE_DIRECT_NFCAST_Manual.pdf" (protocol in sections 2-5: UDP unreliable, self-contained packets, big-endian except deviations; buffer 2000 bytes from page 15; message types 2020/2021 compressed from page 22; no recovery needed from page 9).
- For connections/receiving: Use multicast IP/port from PDFs (configurable in config.json, default to Production Equity NFCAST 227.0.0.21:12996 for real data; warn if market closed—hours 9:00-15:30 IST from docs). Handle UDP nature: delayed/missing/duplicated packets (log but process all).
- Track progress: Update README.md with "What We Did" (e.g., added receiving, filtering, storage; Phase 1 connection integrated), "What We Will Do" (e.g., Phase 3: decoding/decompression), and TODO.md with checkboxes (mark Phase 1 done, add Phase 2 items).
- Explain everything: Deep code comments/docstrings (e.g., why recvfrom(2000)—from manual; how filter types: parse header offsets from analysis docs like BSE_Complete_Technical_Knowledge_Base.md: offset 0-3 zeros, 8-9 LE type 0x07E4 for 2020). In README: explain receiving (infinite loop, filter 2020/2021, extract tokens at offset 36+ LE uint32, store in data/raw_packets/ as .bin files and tokens in JSON).
- Error handling/Logs: Use logging module (import logging; configure in main.py to file/console with levels DEBUG/INFO/ERROR). Log connection success, packet received (len, addr), type check (valid/invalid), token extraction, storage, and errors (e.g., socket timeouts, invalid headers). This tracks where stuck (e.g., "No packets: market closed?").
- Testing: Add test_packet_receiver.py (mock socket.recvfrom with sample packets from docs).
- Running: Main entry point is python src/main.py—it loads config, establishes connection (from Phase 1), starts receiving loop, filters/stores. Assure: Check packet validity (size 300/556 from analysis, leading zeros), log "Received valid 2020 packet with tokens: [list]".

**Phase 2 Focus: Receiving Packets, Filtering, Extracting Tokens, and Storage**
- Assume Phase 1 done: connection.py joins multicast, main.py calls it and logs success.
- Implement receiving: In packet_receiver.py, infinite loop with sock.recvfrom(2000), get packet/addr.
- Filter for 2020/2021: Parse header (36 bytes from knowledge base: offset 0:4 zeros==b'\x00\x00\x00\x00', 4:2 format ID (0x0124/0x022C BE), 8:2 type LE (0x07E4=2020, adjust for 2021=0x07E5? from manual page 22: 2021). If matches, proceed; else log discard.
- Extract tokens: For valid packets, parse records starting offset 36, every 64 bytes (up to 6); token at +0:4 LE uint32 (from analysis: non-zero valid, e.g., 842364 test).
- Store: Raw packets in data/raw_packets/ as timestamped .bin (e.g., 20251003_135214_packet.bin). Extracted tokens per packet in JSON (e.g., {"timestamp": "...", "msg_type": 2020, "tokens": [842364, ...]} ) in data/processed_json/tokens.json (append mode). This prepares for Phase 3 decoding.
- Assure correctness: Log packet details; if no packets, mention "Ensure market open (9AM-3:30PM IST), correct IP/port, IGMP enabled" from manuals.
- Deep Explanation: UDP recv unreliable—handle partial/invalid (check len>=36, header matches deviations from final_analysis.md). Tokens LE while others BE (mixed from docs). Storage for debugging/next phases.
- What's Done/Not Done: Done: Connection+receiving+filter+extract/store (Phase 1+2). Not Done: Full decode/decompress (Phase 3), data collection/save (Phase 4). If forget packets: Explicitly add "Receive and store at least 10 packets before proceeding" in TODO.

**Project Structure:** (Unchanged from Phase 1; update files as needed)
```
bse_udp_reader/
├── .venv/                  # Virtual environment
├── src/
│   ├── __init__.py
│   ├── connection.py       # UDP multicast setup (from Phase 1)
│   ├── packet_receiver.py  # New: Receives, filters 2020/2021, extracts tokens, stores
│   ├── decoder.py          # Placeholder
│   ├── decompressor.py     # Placeholder
│   ├── data_collector.py   # Placeholder
│   ├── saver.py            # Placeholder (will use for JSON in this phase)
│   └── main.py             # Updated: Calls connection, then packet_receiver loop
├── data/
│   ├── raw_packets/        # Store .bin raw packets here
│   ├── processed_json/     # Store tokens JSON here
│   └── processed_csv/      # For future
├── docs/                   # Unchanged
├── tests/
│   ├── test_connection.py  # From Phase 1
│   ├── test_packet_receiver.py # New: Mock receiving/filtering
│   └── test_decompressor.py # Placeholder
├── requirements.txt         # Add logging if needed
├── README.md                # Update progress
├── TODO.md                  # Update checkboxes
└── config.json              # Add "segment": "equity", "store_limit": 100 (max packets to store)
```

**Step-by-Step TODO for Phase 2 (Implement Sequentially):**
1. Update main.py: Load config, call connection.get_socket(), pass to packet_receiver.receive_loop(sock).
2. In packet_receiver.py: Infinite loop recvfrom(2000), log packet len/addr.
3. Filter: Parse header for type 2020/2021; if valid, log "Valid packet received".
4. Extract tokens: Loop records, get LE tokens, collect list; assure non-zero/valid.
5. Store: Write raw to .bin, append tokens dict to JSON; log "Stored packet and tokens".
6. Add logging: Configure in main.py; track stuck (e.g., timeout=5s on recv).
7. Update README/TODO: Mark Phase 2 done, note remaining.

Generate the project updates: Modify existing files, add new code for Phase 2. Output as code snippets or ZIP description.
==========================================================================================================

**Phase 3 Prompt for BSE UDP Market Data Reader Python Project:**

You are an expert Python developer specializing in financial data feeds, network programming, and protocol parsing. This is Phase 3 of the multi-phase project "bse_udp_reader". Building on Phase 1 (project setup, .venv, and UDP multicast connection) and Phase 2 (receiving packets, filtering for 2020/2021 message types, extracting tokens, and storing raw packets/tokens), we now focus on decoding the stored packets, decompressing the compressed sections for 2020/2021 messages, extracting touch line data (open, prev_close, high, low, ltp, volume, best_bid, best_ask) and market depth data (best 5 bid/ask levels with prices, quantities, orders, implied qty), normalizing (e.g., prices /100 to rupees), and saving the processed data to both JSON and CSV. The overall goal is a complete project: connect to BSE Direct NFCAST, receive/filter packets, decode/decompress, collect data, and save.

**Standards to Follow in This and All Future Prompts:**
- Always adhere to the project structure from previous phases.
- Use the .venv virtual environment; assume it's activated and dependencies installed (add 'csv' and 'json' if not in requirements.txt—standard libs; use logging for tracking).
- Read and incorporate details from all provided documents, including the full PDFs "BOLTPLUS Connectivity Manual V1.14.1.pdf" (connection params in section 5, e.g., Equity NFCAST IP/port; no auth for NFCAST) and "BSE_DIRECT_NFCAST_Manual.pdf" (protocol in sections 2-5: compression for 2020/2021 only from Open Rate onwards, pages 48-55: differential 2-byte values, bases LTP/LTQ, special 32767/full read, 32766/-32766 end markers, dynamic cascading bases for best 5; big-endian except deviations; UDP self-contained).
- For decoding/decompression: Follow deviations from other docs (BSE_Final_Analysis_Report.md: leading 0x00000000, format ID 0x0124/0x022C, mixed endian—tokens LE uint32 at offset 36+, prices BE; fixed 64-byte records; field mapping corrections like position 8=prev_close). Header 36 bytes, records every 64 bytes up to 6. Decompress: Uncompressed up to Close Rate + LTQ + LTP, then compressed fields (open, prev_close, high, low, etc.) using diffs + bases; best 5 with cascading (level1 base LTP/LTQ, level2 base level1, etc.).
- Track progress: Update README.md with "What We Did" (e.g., added decoding/decompression, data extraction/save; Phases 1-3 integrated for full run), "What We Will Do" (e.g., enhancements like symbol resolution), and TODO.md with checkboxes (mark Phases 1-2 done, add Phase 3 items).
- Explain everything: Deep code comments/docstrings (e.g., decompression function: "Read 2-byte signed diff, if 32767 read full 4-byte, else base + diff; from manual p49"). In README: explain full flow (connection -> receive/filter/store raw -> decode header/records -> decompress compressed parts -> extract/normalize touch line/depth -> save JSON/CSV). Assure Phases 1-2 work: In main.py, add checks (e.g., if no packets stored, log "Phase 2 failed: No packets—check market hours/connection").
- Error handling/Logs: Enhance logging (DEBUG for packet details, INFO for success, ERROR for issues like invalid diff/decompression fail). Log every step: "Decoding packet: size X", "Decompressing field Y: value Z", "Extracted data for token T", "Saved to JSON/CSV", "Issue: Invalid header—skipping". Track fetching issues (e.g., "No 2020 packets: Market closed? IP wrong?").
- Code Readability: Use clear variable names (e.g., base_ltp, diff_value), functions (e.g., decompress_field(base, packet, offset)), PEP8 style, docstrings. Modular: decoder.py for header/token parse, decompressor.py for diff logic/best5.
- Testing: Add test_decoder.py and test_decompressor.py (mock packets from knowledge base/code examples in docs, assert extracted values match expected).
- Running: Main entry point python src/main.py—full flow: load config, connect (Phase1), receive/filter/extract/store raw/tokens (Phase2 infinite loop), then for each valid packet: decode, decompress, collect data, save to JSON (list of dicts per instrument: {"token":, "timestamp":, "open":, "high":, ... , "bid_levels": [{"price":, "qty":, ...}, ...]}) and CSV (columns: token, timestamp, open, high, ..., bid1_price, bid1_qty, ... ask5_orders; append rows). Timestamped files in data/processed_json/ and processed_csv/ (e.g., 20251003_quotes.json/csv). Run indefinitely, process in real-time.

**Phase 3 Focus: Decoding, Decompression, Data Extraction, and Saving**
- Assume Phases 1-2 working: main.py already connects, receives, filters 2020/2021, stores raw .bin and tokens JSON. Now, integrate: After filtering/extracting in packet_receiver.py, pass packet to decoder.decode_packet(packet) -> decompressor.decompress_records(decoded_data) -> data_collector.collect_quotes(decompressed) -> saver.save_to_json_csv(quotes).
- Decoding: In decoder.py, parse header (36 bytes: check zeros, format ID for size 300/556, type LE, timestamp from offsets 20-25 BE). Then records: for num_records (from header or fixed up to 6), at offsets 36,100,... parse token LE, then uncompressed fields up to LTP (e.g., num_trades BE, volume BE, close_rate BE, ltq BE, ltp BE from manual layouts p48+).
- Decompression: In decompressor.py, start after LTP: for compressed fields (open, prev_close, high, low, reserved, indicative_eq_price, etc.) use _decompress_field(base_ltp/ltq, packet, offset) handling specials. Then best5 buy/sell loops: decompress levels with cascading bases (stop at 32766/-32766). Normalize prices /100.
- Data Collection: In data_collector.py, per record build dict with touch line (from fields) and depth (lists of dicts for bid/ask levels).
- Saving: In saver.py, append to JSON (json.dump with indent=4 for readability) and CSV (csv.writer, header row if new file).
- Assure Completeness: Check Phases 1-2 (e.g., if stored packets exist/load for offline test). Handle 2020 (4-byte token) vs 2021 (8-byte). Log "Full decode success: Extracted X quotes".
- Deep Explanation: Decompression principal (manual p48: diff=base+signed_short, exceeds=32767->full; dynamic for best5 p50). Deviations (analysis: misleading fields, data issues like low LTP). Save both formats for flexibility (JSON structured, CSV tabular).
- What's Done/Not Done: Done: Full project flow (connect-receive-decode-decompress-save). Not Done: Advanced (e.g., subscription/auth if needed from BOLTPLUS, but NFCAST multicast no auth; symbol map from RDI).

**Project Structure:** (Unchanged; update files)
```
bse_udp_reader/
├── .venv/                  # Virtual environment
├── src/
│   ├── __init__.py
│   ├── connection.py       # Phase 1
│   ├── packet_receiver.py  # Phase 2: Updated to call decode/decompress/save
│   ├── decoder.py          # New: Header/record parsing
│   ├── decompressor.py     # New: Decompression logic
│   ├── data_collector.py   # New: Extract/normalize quotes
│   ├── saver.py            # New: JSON/CSV saving
│   └── main.py             # Updated: Full orchestration
├── data/
│   ├── raw_packets/        # Phase 2 .bin
│   ├── processed_json/     # Phase 2 tokens + New quotes JSON
│   └── processed_csv/      # New quotes CSV
├── docs/                   # Unchanged
├── tests/
│   ├── test_connection.py  # Phase 1
│   ├── test_packet_receiver.py # Phase 2
│   ├── test_decoder.py     # New
│   └── test_decompressor.py # New
├── requirements.txt         # Updated if needed
├── README.md                # Update progress
├── TODO.md                  # Update
└── config.json              # Add "subscribed_tokens": [842364], "market_hours_check": true
```

**Step-by-Step TODO for Phase 3 (Implement Sequentially):**
1. In packet_receiver.py: After filter/extract, call decoder.decode_packet(packet) -> return header, records.
2. In decoder.py: Parse header, loop records for uncompressed parts/token.
3. In decompressor.py: For each record, decompress compressed fields/best5, handle specials/cascading.
4. In data_collector.py: Build quote dicts, normalize.
5. In saver.py: Save quotes to JSON/CSV, timestamp files.
6. Update main.py: Integrate full chain in loop; add Phase1-2 checks (e.g., socket alive, packets received).
7. Enhance logs: Every step logged for issue tracking.
8. Update README/TODO: Mark Phase 3 done, note full project runnable.

Generate the project updates: Modify existing, add new code for Phase 3. Output as code snippets or ZIP description.

============================================================================================

**Phase 4 Prompt for BSE UDP Market Data Reader Python Project:**

You are an expert Python developer specializing in financial data feeds, network programming, and protocol parsing. This is Phase 4 of the multi-phase project "bse_udp_reader". Building on Phases 1-3 (Phase 1: project setup and connection; Phase 2: receiving/filtering/extracting/storing raw packets and tokens; Phase 3: decoding/decompressing/extracting touch line and market depth data/saving to JSON/CSV), this phase focuses on the remaining enhancements and final integration to ensure a robust, production-ready system. The overall goal is a fully functional project: connect to BSE Direct NFCAST via UDP multicast, receive/filter 2020/2021 packets, decode/decompress, extract normalized data (touch line: open, prev_close, high, low, ltp, volume, bid, ask; market depth: best 5 bid/ask levels), and save to JSON/CSV, with comprehensive logging and error handling.

**Standards to Follow in This and All Future Prompts:**
- Always adhere to the project structure from previous phases.
- Use the .venv virtual environment; assume it's activated and dependencies installed (requirements.txt includes logging, csv, json, datetime; add 'os' if needed for file handling).
- Read and incorporate details from all provided documents, including the full PDFs "BOLTPLUS Connectivity Manual V1.14.1.pdf" (connection parameters in section 5, e.g., Equity NFCAST IP 227.0.0.21:12996, routes in section 4, IGMPv2 setup) and "BSE_DIRECT_NFCAST_Manual.pdf" (protocol in sections 2-5: UDP unreliable, compression for 2020/2021 from Open Rate onwards, pages 48-55: differential decompression, dynamic bases, special markers 32767/±32766; market hours 9:00-15:30 IST from page 10).
- For enhancements: Integrate optional BOLTPLUS authentication (section 3) if needed (currently NFCAST multicast no auth per manual), add contract/symbol resolution via RDI (section 3.3.1), optimize performance (manual p15: <1ms parsing target), and handle data quality issues (e.g., low LTP from analysis).
- Track progress: Update README.md with "What We Did" (e.g., integrated all phases, added enhancements, assured full run), "What We Will Do" (e.g., real-time testing, WebSocket streaming), and TODO.md with checkboxes (mark Phases 1-3 done, add Phase 4 items).
- Explain everything: Deep code comments/docstrings (e.g., "Optimize recv loop: Batch process 100 packets to hit <1ms per manual p15"). In README: Explain full flow (connect-receive-decode-decompress-save with enhancements), assure Phases 1-3 work (e.g., load stored packets for offline test if live fails), and detail remaining parts (e.g., subscription via BOLTPLUS API not yet implemented).
- Error handling/Logs: Enhance logging (DEBUG for packet details, INFO for milestones, ERROR/WARNING for issues like market closure, invalid data). Log every step: "Connected", "Received X packets", "Decoded Y records", "Decompressed Z fields", "Saved to files", "Warning: LTP too low—validate", "Error: No packets—check hours/IP". Track issues (e.g., "Stuck: No data after 5min—market closed?").
- Code Readability: Maintain PEP8, clear names (e.g., normalized_price, depth_level), modular functions (e.g., validate_quote_data), consistent logging format (timestamp, level, message).
- Testing: Update tests/ with real packet scenarios (e.g., test_decoder.py for data quality checks, test_decompressor.py for edge cases like 32767).
- Running: Main entry point python src/main.py—full flow: load config, connect (Phase 1), receive/filter/extract/store (Phase 2), decode/decompress/collect/save (Phase 3), apply enhancements (Phase 4) in a real-time loop. Assure: Check market hours (current: 05:08 PM IST, Oct 03, 2025—market closed), handle offline mode with stored packets.

**Phase 4 Focus: Final Integration, Enhancements, and Assurance**
- Assume Phases 1-3 working: main.py runs full chain (connect-receive-decode-decompress-save). Now, enhance and assure:
  - **Integration Check:** In main.py, add pre-run validation: if no live packets (market closed 15:30 IST), load stored .bin from data/raw_packets/ for offline processing. Log "Switching to offline mode".
  - **Enhancements:**
    - **Data Quality:** In data_collector.py, add validation (e.g., if ltp < 10 and volume > 0, log "Suspicious LTP: X for token Y—cross-check market"; from analysis LTP=6.82 issue).
    - **Performance:** In packet_receiver.py, batch process (e.g., 100 packets) to hit <1ms parsing (manual p15); log "Processed batch of X packets in Yms".
    - **Symbol Resolution:** In data_collector.py, stub RDI integration (section 3.3.1): if token in config.json["subscribed_tokens"], map to symbol (e.g., 842364 -> "BSX SENSEX Future"); log "Resolved token X to Y".
    - **BOLTPLUS Auth (Optional):** In connection.py, add placeholder for REST API auth (manual section 3) if future subscription needed; log "Auth skipped—NFCAST multicast".
    - **Error Recovery:** In main.py, add reconnection logic (e.g., if socket.error, retry 3x with 5s delay); log "Reconnecting attempt X".
  - **Assurance:** Run full flow, log milestones (e.g., "Phase 1-3 completed, Phase 4 enhancements applied"). If issues (e.g., no 2020/2021 packets), log "Assurance failed: Check Phase 2 filtering or market status".
- **Remaining Parts:** Subscription via BOLTPLUS API (not in NFCAST manual but in BOLTPLUS section 3), advanced features (WebSocket streaming, historical cache) deferred to future.
- **Deep Explanation:** Market closure handling (current 17:08 IST > 15:30 IST); performance optimization (batch vs single packet); data quality (cross-reference with prev_close); RDI stub for scalability. Logs ensure traceability (e.g., "No depth data: End marker 32766 hit").

**Project Structure:** (Unchanged; update files)
```
bse_udp_reader/
├── .venv/                  # Virtual environment
├── src/
│   ├── __init__.py
│   ├── connection.py       # Phase 1 + Optional auth stub
│   ├── packet_receiver.py  # Phase 2 + Batch optimization
│   ├── decoder.py          # Phase 3
│   ├── decompressor.py     # Phase 3
│   ├── data_collector.py   # Phase 3 + Quality/Symbol
│   ├── saver.py            # Phase 3
│   └── main.py             # Updated: Full flow + Assurance
├── data/
│   ├── raw_packets/        # Phase 2 + Offline source
│   ├── processed_json/     # Phase 3
│   └── processed_csv/      # Phase 3
├── docs/                   # Unchanged
├── tests/
│   ├── test_connection.py  # Phase 1
│   ├── test_packet_receiver.py # Phase 2
│   ├── test_decoder.py     # Phase 3
│   └── test_decompressor.py # Phase 3
├── requirements.txt        # Updated if needed
├── README.md               # Update progress
├── TODO.md                 # Update
└── config.json             # Add "batch_size": 100, "retry_attempts": 3
```

**Step-by-Step TODO for Phase 4 (Implement Sequentially):**
1. In main.py: Add offline mode check, integrate full flow.
2. In packet_receiver.py: Implement batch processing.
3. In data_collector.py: Add data validation, symbol stub.
4. In connection.py: Add auth placeholder, reconnection logic.
5. Enhance logging across all files for milestones/issues.
6. Update tests/ with new scenarios.
7. Update README/TODO: Mark Phase 4 done, note future plans.

Generate the project updates: Modify existing, add enhancements. Output as code snippets or ZIP description.
===============================================================================================
**Phase 4 Prompt for BSE UDP Market Data Reader Python Project (Final Assurance and Enhancements):**

You are an expert Python developer specializing in financial data feeds, network programming, and protocol parsing. This is Phase 4 of the multi-phase project "bse_udp_reader". Building on Phases 1-3 (Phase 1: project setup and UDP multicast connection; Phase 2: receiving/filtering/extracting/storing raw packets and tokens; Phase 3: decoding/decompressing/extracting touch line and market depth data/saving to JSON/CSV), this phase focuses on final assurance, enhancing the system for Equity Derivatives and Futures & Options (F&O) market depth and touch line data, verifying all processes (especially token saving and data extraction), and adding comprehensive logging to track every step and troubleshoot issues. The overall goal is a fully functional, production-ready project: connect to BSE Direct NFCAST via UDP multicast, process 2020/2021 packets, extract normalized data (touch line: open, prev_close, high, low, ltp, volume, bid, ask; market depth: best 5 bid/ask levels), and save to JSON/CSV, with robust error handling and logging.

**Standards to Follow in This and All Future Prompts:**
- Always adhere to the project structure from previous phases.
- Use the .venv virtual environment; assume it's activated and dependencies installed (requirements.txt includes logging, csv, json, datetime, os; ensure all standard libs are covered).
- Read and incorporate details from all provided documents, including the full PDFs "BOLTPLUS Connectivity Manual V1.14.1.pdf" (connection parameters in section 5.2 for Equity Derivatives: IP 227.0.0.22:12997, F&O multicast groups; routes in section 4; IGMPv2 setup) and "BSE_DIRECT_NFCAST_Manual.pdf" (protocol in sections 2-5: compression for 2020/2021 from Open Rate onwards, pages 48-55: differential decompression with LTP/LTQ bases, special markers 32767/±32766, dynamic best 5 bases; market hours 9:00-15:30 IST from page 10; buffer size 2000 bytes).
- For enhancements: Switch to Equity Derivatives segment (section 5.2) for F&O data, validate token saving (ensure all extracted tokens are stored in JSON), assure data completeness (touch line and depth for 2020/2021), and optimize logging for issue tracking.
- Track progress: Update README.md with "What We Did" (e.g., switched to Derivatives, verified token saving, enhanced logging), "What We Will Do" (e.g., real-time testing, RDI integration), and TODO.md with checkboxes (mark Phases 1-3 done, add Phase 4 items).
- Explain everything: Deep code comments/docstrings (e.g., "Switch to Derivatives IP: 227.0.0.22:12997 from manual 5.2"). In README: Explain full flow with Derivatives focus, assure Phases 1-3 work (e.g., load stored packets if live fails), detail logs for troubleshooting (e.g., "No tokens saved: Check Phase 2 extraction").
- Error handling/Logs: Use logging module (DEBUG for packet details, INFO for milestones, WARNING/ERROR for issues). Log every step: "Connected to Derivatives", "Received packet size X", "Extracted Y tokens", "Saved to JSON/CSV", "Warning: No depth data—end marker hit", "Error: Invalid packet—skipping". Track issues (e.g., "Stuck: No packets—market closed at 18:26 IST?").
- Code Readability: Maintain PEP8, clear names (e.g., derivatives_ip, token_list), modular functions (e.g., verify_token_saving), consistent logging (timestamp, level, message).
- Testing: Update tests/ with Derivatives scenarios (e.g., test_packet_receiver.py for 227.0.0.22:12997, test_decoder.py for F&O data validation).
- Running: Main entry point python src/main.py—full flow: load config, connect to Equity Derivatives, receive/filter/extract/store (Phase 2), decode/decompress/collect/save (Phase 3), verify tokens/data, log extensively. Assure: Check market hours (current: 18:26 IST, Oct 03, 2025—closed; use offline mode with stored packets).

**Phase 4 Focus: Final Assurance, Derivatives Switch, Token/Data Verification, and Logging**
- Assume Phases 1-3 working: main.py runs full chain (connect-receive-decode-decompress-save). Now, enhance and assure:
  - **Integration Check:** In main.py, validate Phases 1-3: if no live packets (market closed 15:30 IST), load stored .bin from data/raw_packets/ for offline processing. Log "Switching to offline mode with X packets".
  - **Switch to Equity Derivatives:** In connection.py, update config to use 227.0.0.22:12997 (manual 5.2) for F&O data. Log "Switched to Equity Derivatives NFCAST".
  - **Token Verification:** In packet_receiver.py and data_collector.py, ensure all extracted tokens (LE uint32 at offset 36+) are saved to data/processed_json/tokens.json. Add verify_token_saving() to check file against received packets; log "Verified X tokens saved" or "Warning: Y tokens missing".
  - **Data Completeness:** In data_collector.py, assure touch line (open, prev_close, high, low, ltp, volume, bid, ask) and market depth (best 5 bid/ask prices, qty, orders, implied qty) for 2020/2021. Validate against manual layouts (p48-55); log "Extracted complete data for token X" or "Error: Missing depth—check decompression".
  - **Logging Enhancement:** Add print/log statements everywhere (e.g., "Decoding record at offset 36", "Decompressing open rate: base LTP + diff", "Saving quote for token 842364"). Use consistent format (e.g., "[HH:MM:SS] [LEVEL] Message").
  - **Assurance:** Run full flow, log milestones (e.g., "Phase 4 complete: Derivatives data processed"). If issues (e.g., no 2020/2021 packets), log "Assurance failed: Check Derivatives IP/market hours".
  - **Remaining Parts:** Real-time subscription (BOLTPLUS API section 3), advanced features (WebSocket, caching) deferred.
- **Analysis of Logs:** From your run (18:08 IST, Oct 03, 2025), market closed (15:30 IST), using simulation (226.1.0.1:11401). Logs show connection success, 4944 tokens loaded, but no packet reception (loop stuck at "Starting packet reception loop..."—expected as market closed). Suggest switching to Derivatives and offline mode.

**Project Structure:** (Unchanged; update files)
```
bse_udp_reader/
├── .venv/                  # Virtual environment
├── src/
│   ├── __init__.py
│   ├── connection.py       # Phase 1 + Derivatives IP
│   ├── packet_receiver.py  # Phase 2 + Token verification
│   ├── decoder.py          # Phase 3
│   ├── decompressor.py     # Phase 3
│   ├── data_collector.py   # Phase 3 + Data completeness
│   ├── saver.py            # Phase 3
│   └── main.py             # Updated: Full flow + Assurance
├── data/
│   ├── raw_packets/        # Phase 2 + Offline source
│   ├── processed_json/     # Phase 2 tokens + Phase 3 quotes
│   └── processed_csv/      # Phase 3 quotes
├── docs/                   # Unchanged
├── tests/
│   ├── test_connection.py  # Phase 1
│   ├── test_packet_receiver.py # Phase 2 + Derivatives
│   ├── test_decoder.py     # Phase 3
│   └── test_decompressor.py # Phase 3
├── requirements.txt        # Updated if needed
├── README.md               # Update progress
├── TODO.md                 # Update
└── config.json             # Update "ip": "227.0.0.22", "port": 12997, "segment": "equity_derivatives"
```

**Step-by-Step TODO for Phase 4 (Implement Sequentially):**
1. In main.py: Add offline mode, validate Phases 1-3.
2. In connection.py: Switch to 227.0.0.22:12997.
3. In packet_receiver.py: Add verify_token_saving().
4. In data_collector.py: Ensure touch line/depth, validate data.
5. Enhance logging/print everywhere (e.g., "Processing packet at offset X").
6. Update tests/ with Derivatives cases.
7. Update README/TODO: Mark Phase 4 done, note future plans.

Generate the project updates: Modify existing, add enhancements. Output as code snippets or ZIP description.